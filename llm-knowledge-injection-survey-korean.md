# 대규모 언어 모델에 도메인 특화 지식 주입: 종합적 서베이

**Injecting Domain-Specific Knowledge into Large Language Models: A Comprehensive Survey**

Zirui Song¹*, Bin Yan²*, Yuhan Liu³, Miao Fang², Mingzhe Li⁴, Rui Yan⁵, Xiuying Chen¹†

¹Mohamed bin Zayed University of Artificial Intelligence  
²Northeastern University  
³Gaoling School of Artificial Intelligence, Renmin University of China  
⁴ByteDance  
⁵Wuhan University

E-mail: zirui.song@mbzuai.ac.ae, xiuying.chen@mbzuai.ac.ae

## 초록 (Abstract)

대규모 언어 모델(Large Language Models, LLMs)은 자연어 이해, 텍스트 요약, 기계 번역과 같은 다양한 작업에서 놀라운 성공을 보여주었습니다. 그러나 범용적 특성으로 인해 의료, 화학, 법률 분석과 같은 전문 지식이 필요한 도메인 특화 응용 분야에서는 효과성이 제한됩니다. 이를 해결하기 위해 연구자들은 도메인 특화 지식을 통합하여 LLM을 향상시키는 다양한 방법을 탐구해왔습니다. 본 서베이에서는 이러한 방법들을 네 가지 핵심 접근법으로 분류하여 종합적으로 개관합니다: 동적 지식 주입(dynamic knowledge injection), 정적 지식 임베딩(static knowledge embedding), 모듈식 어댑터(modular adapters), 프롬프트 최적화(prompt optimization). 각 접근법은 LLM에 도메인 전문성을 부여하는 고유한 메커니즘을 제공하며, 유연성, 확장성, 효율성 간의 트레이드오프를 균형있게 조절합니다. 우리는 이러한 방법들이 어떻게 LLM이 전문화된 작업을 수행할 수 있도록 하는지 논의하고, 장단점을 비교하며, 도메인 특화 LLM을 범용 LLM과 비교 평가하고, 이 신흥 분야의 도전과 기회를 강조합니다. 이 분야를 더 깊이 탐구하는 데 관심이 있는 연구자들을 위해 일반적으로 사용되는 데이터셋과 벤치마크도 요약합니다. 연구자들에게 최신 연구를 업데이트하기 위해, 우리는 전문화된 LLM 분야의 연구를 문서화하는 데 전념하는 오픈소스를 official-repo.com에서 유지관리합니다.

## 1. 서론 (Introduction)

LLM은 다양한 작업에서 놀라운 성공을 거두었으며, 추론, 지식 표현, 의사결정에서 놀라운 능력을 보여주었습니다(Song et al., 2025; Xu et al., 2025). 그러나 범용 응용 분야에서의 인상적인 성능에도 불구하고, 의료, 화학, 법률 분석과 같은 많은 전문 도메인들은 높은 정확도와 신뢰성을 달성하기 위해 도메인 특화 지식의 통합을 요구합니다. 이러한 도전을 해결하기 위해 연구자들은 외부 또는 내장된 도메인 전문성을 통해 LLM을 향상시키는 방법을 탐구해왔으며, 이 과정을 흔히 지식 주입(knowledge injection)이라고 부릅니다(그림 1 참조). 이 접근법은 범용 언어 이해와 도메인 특화 작업의 엄격한 요구사항 간의 격차를 해소하여 LLM이 고도로 전문화된 맥락에서 효과적으로 수행할 수 있도록 하는 것을 목표로 합니다.

범용 LLM의 기초 능력을 바탕으로, 지식 주입 기술은 전문화된 응용 프로그램을 처리하는 데 있어 그들의 한계를 해결하는 효과적인 수단을 제공합니다. 표준 LLM의 일반화된 접근법과 비교하여, 지식 주입은 두 가지 주요 이점을 제공합니다: 1) 전문화된 작업에서 정확도와 신뢰성을 향상시키기 위해 정확한 도메인 특화 지식을 통합, 2) LLM이 새로운 정보나 진화하는 지식 베이스에 동적으로 적응할 수 있도록 하여 최신 전문성을 보장. 이러한 기술들은 구조화된 지식 소스와 비구조화된 지식 소스를 모두 활용하여 범용 이해와 도메인 특화 요구사항 간의 격차를 해소합니다. 결과적으로, 지식 주입 방법은 의료, 화학, 법률 분석과 같은 분야에서 성공적으로 적용되어 LLM 성능을 크게 향상시켰습니다. 예를 들어, 생물의학 LLM(Cho and Lee, 2025; Bolton et al., 2024; Yan et al., 2023)은 의료 진단 및 규제 준수와 같은 작업에서 우수한 정확도를 보여주었으며, 재료 과학을 위한 도메인 특화 모델(Tang et al., 2025a; Xie et al., 2024; Antunes et al., 2024; Zhang et al., 2024b)은 재료 특성 예측 및 발견에서 발전을 이루었습니다. 이러한 전용 모델들은 도메인 지식을 LLM에 통합하는 것의 변혁적 잠재력을 강조합니다.

이러한 발전에도 불구하고, 지식 주입의 초기 노력들은 종종 도메인을 독립적으로 다루었으며, 이는 방법론과 평가의 표준화 부족으로 이어졌습니다. 연구량이 계속 급속히 증가하고 응용 프로그램과 연구가 여러 분야에 걸쳐 확산되면서, 종합적인 검토의 필요성이 명백해집니다. 이 검토는 지식 주입 기술의 현황을 요약하고, 향후 연구를 위한 체계적인 청사진을 제공하며, 확장성과 도메인 특화 정확도의 균형 및 효율적인 실시간 지식 업데이트 활성화와 같은 주요 도전 과제를 식별하는 것을 목표로 합니다.

섹션 2에서는 도메인 특화 지식과 LLM에서의 역할에 대한 배경으로 시작합니다. 섹션 3에서는 네 가지 지식 주입 패러다임의 통합 프레임워크를 제시합니다: (1) 추론 시 동적 지식 주입; (2) 훈련 또는 파인튜닝 중 정적 지식 임베딩; (3) 파라미터 효율적 통합을 위한 모듈식 어댑터; (4) 신중하게 설계된 입력을 통한 프롬프트 최적화. 섹션 4에서는 재료 과학, 화학, 생물학, 법률과 같은 도메인에 걸쳐 이러한 방법들을 검토합니다. 섹션 5에서는 주요 데이터셋, 도구 및 비교 결과를 요약합니다. 섹션 6에서는 확장성, 견고성, 도메인 전이를 포함한 개방된 도전 과제를 개괄합니다. 마지막으로 섹션 7에서는 논문을 결론짓고 향후 방향을 반영합니다.

## 2. 배경 (Background)

### 2.1 도메인 특화 지식 (Domain-Specific Knowledge)

도메인 특화 지식은 특정 분야나 응용 프로그램과 관련된 전문 정보나 전문성을 의미하며, 여러 도메인에 걸친 일반 지식과 구별됩니다. 일반 지식이 모델이 광범위한 맥락을 이해할 수 있게 하는 반면, 도메인 특화 지식은 정확하고 분야별 이해가 필요한 전문화된 작업을 다루는 데 필수적입니다(Wang et al., 2025; Li et al., 2025a; Zhang et al., 2025). 예를 들어, 과학 텍스트 처리(Bran et al., 2023)에서 모델은 정확하고 관련성 있는 답변을 제공하기 위해 복잡한 과학 용어, 개념 및 방법론을 이해해야 합니다. 전자상거래 검색(Zhao et al., 2024a)에서는 제품 카테고리, 기술 사양 또는 구어체 쇼핑 언어와 같은 도메인 특화 용어를 이해하는 것이 관련 검색 결과와 추천을 제공하는 데 중요합니다. 의료 응용 프로그램에서 LLM은 의학 용어, 진단, 치료 계획 및 약물 상호작용을 이해해야 합니다. 예를 들어, 생물의학 질문 답변(Singhal et al., 2025; Pei et al., 2024) 및 의료 보고서 요약은 PubMed(Dernoncourt and Lee, 2017)와 같은 의학 문헌의 지식 통합에 의존합니다. 이러한 요구를 해결하기 위해 연구자들은 도메인 특화 지식을 LLM에 통합하는 다양한 방법을 탐구했습니다. 이 논문에서는 이러한 다양한 주입 방법에 대한 서베이를 제공하고자 합니다.

### 2.2 지식 표현 및 인코딩 (Knowledge Representation and Encoding)

지식은 구조와 응용 요구에 따라 다양한 형태를 취할 수 있습니다. 지식 그래프(Liao et al., 2025; Zhang et al., 2024d)는 엔티티와 그들의 관계를 구조화된 그래프로 인코딩하여 질문 답변과 같은 작업에서 추론과 추론을 지원합니다. 반대로 Wikipedia(Jeong et al., 2024)와 같은 텍스트 기반 소스는 풍부하지만 비구조화된 정보를 제공하여 광범위한 맥락적 이해가 필요한 작업에 유용합니다. 지식은 텍스트나 그래프 형태가 아닌 벡터 공간에도 저장될 수 있습니다. 예를 들어, soft prompt tuning(Peng et al., 2025; Singhal et al., 2023a)은 유용한 정보를 벡터로 임베딩하여 특정 작업에서 LLM을 안내하기 위해 입력에 추가합니다. 외부 형태를 넘어, 지식은 내부적으로도 나타날 수 있습니다: chain-of-thought prompting(Sanwal, 2025; Yao et al., 2024)은 LLM이 복잡한 문제를 분해하고 내부 지식에 더 효과적으로 접근할 수 있도록 돕는 중간 추론 단계를 도입합니다—추론, 다단계 계산 또는 의사결정과 관련된 작업에서 성능을 향상시킵니다.

### 2.3 지식 주입 서베이 (Knowledge Injection Survey)

지식 향상 언어 모델에 대한 이전 서베이들은 초점과 범위가 다양합니다. 가장 관련성이 높은 작업은 다음과 같습니다: Cadeddu et al. (2024)는 과학 논문 분류에 초점을 맞추고 실용적인 통찰력을 제공하지만 더 넓은 방법론적 일반화가 부족합니다; Wang et al. (2024b)는 지식 편집에 초점을 맞추고 최소한의 부작용으로 내부 모델 지식을 업데이트하는 것을 목표로 합니다; Hu et al. (2023)은 작업 유형과 지식 소스를 기반으로 지식 향상 모델을 분류하여 모델 중심 관점을 채택하지만, 주로 BERT 및 ERNIE와 같은 LLM 이전 아키텍처를 다룹니다. 이와 대조적으로, 우리의 작업은 LLM의 지식 주입에 대한 통합된 관점을 제시하며, 다양한 작업에 걸친 외부 지식 통합을 통한 능력 향상을 강조합니다.

## 3. 지식 주입의 패러다임 (Paradigms of Knowledge Injection)

도메인 지식이 LLM에 통합되는 방법을 체계적으로 이해하기 위해, 우리는 기존 접근법을 지식이 통합되는 시점과 모델과 상호작용하는 방식에 따라 네 가지 패러다임으로 분류합니다(그림 2 참조). 구체적으로, 정적 지식 주입(Static Knowledge Injection)과 모듈식 지식 어댑터(Modular Knowledge Adapters)는 추론 이전에 지식을 통합하고 전체 파인튜닝 또는 어댑터 기반 튜닝을 통해 파라미터 업데이트를 포함합니다. 반대로, 동적 지식 주입(Dynamic Knowledge Injection)과 프롬프트 최적화(Prompt Optimization)는 모델 파라미터를 변경하지 않고 추론 시 지식을 주입합니다: 전자는 외부 정보를 검색하고, 후자는 설계된 프롬프트를 통해 내부 지식을 활용합니다. 우리는 프로세스를 체계적으로 표현하기 위해 표 1에 설명된 통합 표기법을 활용합니다.

**표 1: 기호 요약**
| 기호 | 설명 |
|------|------|
| x | LLM에 대한 입력 |
| y | LLM의 출력 |
| M | 백본 LLM 함수 |
| K | 외부 도메인 지식 베이스 |
| θ | LLM의 파라미터 |
| ϕ | 도입된 추가 파라미터 |
| R(x, K) | 입력 x가 주어졌을 때 K의 관련 요소를 가져오는 검색 함수 |
| M(x; θ) | 입력 x를 받아 θ로 매개변수화된 출력을 생성하는 LLM 표현 |
| Δθ | 원래 LLM 파라미터에 대한 오프셋 |

### 3.1 동적 지식 주입 (Dynamic Knowledge Injection)

우리는 동적 지식 주입을 외부 지식 베이스나 지식 그래프에서 정보를 먼저 검색한 다음 LLM에서 사용하기 위해 입력과 결합하는 프로세스로 정의합니다:

```
y = M(x, R(x, K); θ)     (1)
```

여기서 x는 원래 입력을 나타내고, R은 검색 함수를 나타내며, K는 외부 지식 베이스이고, θ는 변경되지 않는 모델 파라미터입니다. 이 패러다임은 쉬운 업데이트(따라서 "동적 주입"이라는 용어) 및 모델 재훈련 없이 새로운 지식을 통합할 수 있는 능력을 포함한 여러 이점을 제공합니다. 그러나 지식 베이스 K의 품질, 검색 함수 R, LLM의 최대 입력 길이로 인한 제한과 같은 도전 과제도 제시합니다. 검색 품질을 개선하기 위해 일반적으로 사용되는 기술에는 문장 임베딩에 기반한 의미론적 매칭과 빠른 유사성 검색을 위한 효율적인 벡터 데이터베이스가 포함됩니다.

### 3.2 정적 지식 임베딩 (Static Knowledge Embedding)

동적 지식 검색과 비교하여, 정적 지식 임베딩은 전체 또는 부분 파인튜닝을 통해 지식을 모델의 파라미터에 임베딩하는 것을 포함하여 변경에 덜 유연합니다. 구체적으로, 모델은 K의 도메인 지식을 인코딩하는 새로운 파라미터 Δθ를 학습합니다:

```
Δθ = arg minθ Σ(xs,ys)∈K L(M(xs; θ), ys)
```

여기서 K는 훈련 샘플 xs와 ys를 포함하는 도메인 특화 지식 베이스이고, L은 훈련 손실 함수입니다. 최적화 후 업데이트된 파라미터 Δθ가 얻어집니다.

추론 시에는 추가 검색이나 외부 지식 호출이 필요하지 않습니다: `y = M(x; Δθ)`. 이 패러다임은 추가 검색 단계의 필요성을 제거하여 빠른 추론을 가능하게 하고 종종 더 강력한 성능을 제공합니다. 그러나 도메인 지식이 변경될 때 파인튜닝이 필요하므로 높은 업데이트 비용과 같은 도전 과제도 제시하며, 크거나 자주 변경되는 지식 베이스를 임베딩하려면 상당한 계산 자원이 필요하므로 확장성 문제가 있습니다.

### 3.3 모듈식 지식 어댑터 (Modular Knowledge Adapters)

정적 지식 임베딩과 관련된 비용이 많이 드는 업데이트를 해결하기 위해, 모듈식 지식 어댑터로 알려진 또 다른 패러다임은 계산 자원을 절약하면서 도메인 특화 지식을 저장하기 위해 기본 모델에 삽입하거나 함께 작동할 수 있는 작고 훈련 가능한 모듈을 도입합니다. 이 접근법에서 LLM의 원래 파라미터 θ는 일반적으로 동결되어 모델의 범용 능력을 보존합니다. 지식 데이터셋 K가 주어지면, 어댑터 파라미터 ϕ는 다음 목적을 최소화하여 훈련됩니다:

```
ϕ = arg minϕ Σ(xs,ys)∈K L(M(xs; θ, ϕ), ys)
```

여기서 M(xs; θ, ϕ)는 새로운 어댑터 파라미터로 향상된 기본 모델의 생성 함수를 나타냅니다. 추론 시 향상된 모델은 다음과 같이 출력을 생성합니다: `y = M(x; θ, ϕ)`. 이 패러다임은 원래 모델 가중치를 수정하지 않고 LLM을 특정 도메인에 적응시키는 파라미터 효율적인 방법을 제공합니다. 기본 모델의 파라미터를 동결함으로써, 이 접근법은 새로운 도메인 특화 정보의 원활한 통합을 가능하게 하면서 이전에 획득한 지식을 보존하려고 합니다. 그러나 이 접근법은 새로운 아키텍처 구성 요소를 설계하고 어댑터의 크기와 수를 포함한 적절한 하이퍼파라미터를 결정해야 하는 필요성과 같은 도전 과제도 도입합니다. 이러한 추가 요소는 모델과 훈련 프로세스의 전반적인 복잡성을 증가시킬 수 있습니다.

### 3.4 프롬프트 최적화 (Prompt Optimization)

프롬프트 최적화는 효과적인 텍스트 프롬프트를 작성하여 LLM이 도메인 특화 작업을 수행하도록 안내하는 관행을 의미합니다. 검색 기반 방법과 달리, 모델의 내부 지식에 전적으로 의존하며 외부 지식 베이스나 파인튜닝에 대한 접근이 필요하지 않습니다. 프로세스는 다음과 같이 형식화할 수 있습니다:

```
p* = arg minp L(M([p, x]; θ), y*)
```

여기서 p는 도메인 관련 단서를 포함하는 프롬프트이고, x는 작업 입력이며, θ는 LLM의 고정된 파라미터입니다.

이 패러다임은 가벼운 배포, 훈련 오버헤드 없음, 도메인 간 적응성과 같은 실용적인 이점을 제공합니다. 그러나 정확한 응답을 이끌어내는 프롬프트를 설계하는 것이 간단하지 않을 수 있고, 긴 프롬프트가 컨텍스트 길이 제한으로 인해 사용 가능한 입력 공간을 줄일 수 있다는 주요 도전 과제도 직면합니다. 프롬프트 기반 접근법은 수동 프롬프팅, 프롬프트 튜닝, 접두사 튜닝으로 광범위하게 분류할 수 있습니다. 이들은 프롬프트가 구성되거나 최적화되는 방식에서 차이가 있습니다—이산적이고 정적인 프롬프트에서 학습 가능한 임베딩까지—그리고 저자원 도메인 적응을 위해 널리 채택되었습니다.

### 3.5 네 가지 패러다임의 비교 (Comparison of the Four Paradigms)

**표 2: 훈련 비용, 추론 속도 및 제약 조건별 주입 방법 선택 가이드**

| 패러다임 | 훈련 비용 | 추론 속도 | 제한사항 |
|----------|-----------|-----------|----------|
| 동적 주입 | 없음, 그러나 검색 모듈 필요 | 검색 지연으로 인해 느림 | 검색 품질에 크게 의존 |
| 정적 임베딩 | 높음 (사전훈련 또는 파인튜닝 필요) | 추가 비용 없음 | 고정된 지식; 재앙적 망각 위험 |
| 모듈식 어댑터 | 낮음 (파라미터의 작은 부분집합 훈련) | 거의 영향 없음 | 훈련 데이터 품질에 민감 |
| 프롬프트 최적화 | 없음 | 거의 영향 없음 | 노동 집약적; 기존 지식에 제한 |

동적 지식 주입은 런타임에 외부 지식을 도입하여 추가 훈련 비용 없이 유연성과 적응성을 제공합니다. 그러나 효율적인 검색에 의존하며, 검색 성능이 좋지 않으면 추론 속도가 저하될 수 있습니다. 정적 지식 임베딩은 사전훈련 또는 파인튜닝 중에 도메인 전문성을 통합하여 대규모 데이터와 상당한 계산 자원이 필요합니다. 추론 비용을 추가하지 않지만 새로운 정보에 적응하는 데 어려움을 겪고 재앙적 망각에 취약합니다. 모듈식 어댑터는 최소한의 훈련 데이터가 필요한 플러그 앤 플레이 모듈을 통해 도메인 능력을 향상시킴으로써 중간 지점을 제공합니다. 소수의 파라미터만 훈련되어 비용을 줄이고 추론 속도를 보존하지만, 성능은 데이터 품질에 크게 의존합니다. 프롬프트 최적화는 잘 작성된 입력을 사용하여 재훈련을 피합니다. 빠른 추론을 유지하지만 상당한 수동 노력에 의존하며 새로운 정보를 통합하는 것보다 기존 지식을 활성화하는 것으로 제한됩니다. 우리는 특정 요구사항과 시나리오에 따라 적합한 방법을 결정하는 데 도움이 되는 실용적인 가이드로서 이러한 비교를 표 2에 요약합니다.

## 4. 응용 분야 (Applications)

### 4.1 금융 (Finance)

금융 도메인에서 LLM은 일반적으로 두 가지 주요 개발 경로를 따릅니다: 금융 작업에 대한 범용 모델 파인튜닝 또는 도메인 특화 코퍼스를 사용한 처음부터 모델 훈련. 파인튜닝의 경우, PIXIU(Xie et al., 2023)는 136K 금융 지시 샘플을 사용하여 LLaMA를 적응시켜 모델이 다양한 금융 관련 시나리오를 처리할 수 있도록 합니다. Instruct-FinGPT(Zhang et al., 2023)는 두 개의 금융 감정 데이터셋에서 10K 샘플로 파인튜닝하여 감정 분류에 초점을 맞춥니다. FinGPT(Yang et al., 2023)는 FinLLM 개발을 위한 엔드투엔드 프레임워크를 제안하여 LoRA를 통해 50K 샘플로 LLaMA와 ChatGLM을 효율적으로 파인튜닝하여 계산 비용을 크게 줄입니다. 대조적으로, 처음부터 훈련된 FinLLM은 처음부터 깊은 도메인 정렬을 목표로 합니다. BloombergGPT(Wu et al., 2023b)는 금융 응용 프로그램에 전문화하기 위해 5B Bloomberg 특화 토큰(전체 코퍼스의 0.7%)을 사용합니다. XuanYuan 2.0(Zhang and Yang, 2023)은 366B 토큰으로 훈련되고 13B로 파인튜닝된 가장 큰 중국 금융 챗봇입니다. Fin-T5(Lu et al., 2023)는 T5 아키텍처를 사용하여 300GB 중국 금융 코퍼스를 활용하며, SNFinLLM(Zhao et al., 2024a)은 실시간 금융 데이터 주입을 통해 추론을 향상시킵니다.

요약하면, 이 분야는 가벼운 튜닝에서 포괄적인 엔드투엔드 개발까지 훈련 전략의 풍부한 다양성을 보여줍니다.

### 4.2 생물의학 (Biomedicine)

생물의학 도메인은 PubMed(Dernoncourt and Lee, 2017) 및 MedQA(Jin et al., 2021)와 같은 전문 코퍼스의 풍부함으로부터 이익을 얻어 생물의학 텍스트에 특별히 훈련된 LLM의 개발을 가능하게 합니다. 이러한 모델들은 종종 생물의학 데이터의 도메인 특화 풍부함을 활용하여 정적 지식 임베딩 접근법을 따릅니다. 예를 들어, PMC-LLaMA(Wu et al., 2023a)는 S2ORC 데이터셋(Lo et al., 2020)에서 큐레이션된 490만 PubMed Central 논문에 대한 추가 사전훈련을 통해 LLaMA 7B 모델을 확장하여 생물의학 지식을 효과적으로 임베딩하기 위해 5 에포크를 완료합니다. 유사하게, Med-PaLM 2(Singhal et al., 2023b)는 지시 파인튜닝을 통해 PaLM 2를 기반으로 구축됩니다. 이 파인튜닝은 MedQA, MedMCQA(Pal et al., 2022), HealthSearchQA(Singhal et al., 2023a)를 포함한 다양한 의료 질문-답변 데이터셋을 통합합니다.

기초 모델을 넘어서, 외부 도구와 지식을 통합하면 성능을 더욱 향상시킬 수 있습니다. GeneGPT(Jin et al., 2024)는 코드 사전훈련된 LLM을 활용하여 NCBI Web API를 호출하여 GeneTuring 테스트를 처리하며, API 요청을 식별하고 실행할 수 있는 증강된 디코딩 알고리즘과 컨텍스트 내 학습을 결합합니다. Med-PaLM(Singhal et al., 2023a)은 추론 중에 의료 도메인 지식을 저장하고 검색하도록 설계된 밀집 표현인 벡터 프롬프트 사용을 통해 Flan-PaLM(Chung et al., 2024)의 기능을 확장합니다.

전반적으로 생물의학 LLM은 정적 사전훈련, 지시 튜닝, 도구 통합을 결합하는 데 선도적이며, 전문화된 AI에서 하이브리드 추론으로의 전환을 반영합니다.

### 4.3 재료과학 (Materials)

생물의학 도메인과 대조적으로, 재료 과학 및 화학 분야는 주로 정적 지식 임베딩에 초점을 맞추었습니다. 많은 모델들이 향상된 작업 성능을 위해 일반 모델을 파인튜닝하기 위해 도메인 특화 코퍼스에 의존합니다. Darwin 1.5(Xie et al., 2024)는 자연어 입력을 사용하여 재료 발견의 성능을 향상시키는 2단계 훈련 전략을 채택합니다. ScholarChemQA(Chen et al., 2024)는 화학 추론을 개선하기 위해 BERT와 LLaMA를 파인튜닝하는 화학 QA 데이터셋을 구성합니다. 최근 일부 노력은 동적 지식 통합을 탐구하기 시작했습니다. ChemCrow(Bran et al., 2023)는 합성 및 약물 발견과 같은 응용 프로그램을 위해 화학 도구로 LLM을 증강합니다. ChemAgent(Tang et al., 2025b)는 잘 설계된 계획 프롬프트가 내부 추론을 활용하여 복잡한 실행 작업을 통해 모델을 안내할 수 있음을 보여줍니다.

아직 초기 단계에 있지만, 이 분야는 정적 임베딩에서 대화형 및 도구 증강 추론으로 전환하고 있어 향후 개발에 대한 강력한 잠재력을 나타냅니다.

### 4.4 인간 중심 과학 (Human-Centered Science)

인간 중심 과학은 인간의 행동, 요구 및 결정을 이해하고 지원하는 데 초점을 맞춥니다. 이 학제간 도메인에는 정신 건강, 교육, 사회적 행동 예측 및 법적 추론이 포함되며, 각각 개인화되고 맥락 인식 LLM의 이점을 얻습니다.

정신 건강에서 PsyQA(Sun et al., 2021)와 같은 데이터셋은 심리 상담 시나리오에서 모델 훈련을 위한 기초를 제공합니다. SoulChat(Chen et al., 2023)은 정적 지식 임베딩을 사용하여 100,000개 이상의 장문 상담 세션에 파인튜닝된 모델로 공감적 대화를 위해 설계되었습니다. 대조적으로, MeChat(Qiu et al., 2023)은 실시간 입력에 적응하기 위해 동적 지식 주입을 사용하여 감정 지원 능력을 향상시킵니다. 이러한 발전은 개인화되고 맥락 인식 솔루션을 통해 복잡한 실제 과제를 해결하는 인간 중심 과학의 잠재력을 보여줍니다.

교육 도메인에서 LLM은 개인화된 학습, 커리큘럼 정렬 및 대화형 교육과 같은 과제를 해결하는 데 엄청난 잠재력을 보여주었습니다. 예를 들어, 개인화된 학습은 모델이 개별 요구에 적응하여 맞춤형 피드백과 감정 지원을 제공해야 합니다. EduChat(Dan et al., 2023)은 Q&A, 쓰기 피드백 및 감정 지도와 같은 작업을 지원하기 위해 정적 지식 임베딩을 통해 심리학 및 교육학 이론을 적용합니다. 유사하게, QiaoBan(Weixiang et al., 2023)은 프롬프트 최적화를 사용하여 모델 행동을 어린이의 심리적 및 감정적 요구에 맞게 조정합니다. 도메인 특화 교육과 대화형 교육도 발전을 보았습니다. CyberQ(Agrawal et al., 2024)는 AISecKG(Agrawal, 2023)를 통해 정적 지식 임베딩과 동적 지식 주입을 혼합하여 사이버 보안 모범 사례를 기반으로 Q&A를 생성합니다. 한편, 대화형 교육은 SocraticLM(Liu et al., 2024c)과 같은 모델로부터 이익을 얻으며, 이는 학생들을 비판적 사고와 문제 해결에 참여시키기 위해 SocraTeach 데이터셋에 파인튜닝된 어댑터를 사용합니다.

사회 과학의 경우, SocialLLM(Jiang and Ferrara, 2023)과 같은 모델은 정적 지식 임베딩과 동적 지식 주입을 결합하여 소셜 네트워크에서 인간 행동을 분석합니다. SSF(Wang et al., 2024a), FPS(Liu et al., 2024e) 및 FUSE(Liu et al., 2025b)와 같은 모델은 프롬프트 최적화를 사용하여 소셜 네트워크에서 가짜 뉴스의 확산과 진화를 시뮬레이션하여 잘못된 정보의 영향을 이해하는 데 도움을 줍니다. 또한 (Liu et al., 2025a)는 데이터를 합성하는 다중 에이전트 접근법을 채택하여 이를 지식으로 사용하여 가짜 뉴스 탐지를 위한 언어 모델을 향상시킵니다.

주류 모델과 그들의 정보 요약은 표 3에 제공됩니다. 다양한 도메인에 걸친 더 많은 모델은 official-repo에서 찾을 수 있습니다.

## 5. 도구, 리소스 및 분석 (Tools, Resources, and Analysis)

### 5.1 지식 주입 프레임워크 (Knowledge Injection Framework)

이 섹션에서는 이해와 적용을 용이하게 하기 위해 다양한 지식 주입 방법으로 분류된 네 가지 오픈소스 프레임워크에 대한 자세한 소개를 제공합니다: 동적 지식 주입을 위한 KnowGPT(Zhang et al., 2024d), 정적 지식 임베딩을 위한 StructTuning(Liu et al., 2024d), 모듈식 지식 어댑터를 위한 K-Adapter(Wang et al., 2021), 프롬프트 최적화를 위한 SelfLift(Cheng et al., 2024).

**KnowGPT**는 강화 학습을 활용하여 지식 그래프에서 매우 관련성 높은 하위 그래프를 추출함으로써 지식 그래프와 프롬프트 최적화를 동적으로 결합합니다. 이러한 하위 그래프는 트리플로 표현되고 다양한 프롬프트 템플릿을 통해 언어 모델이 해석하고 활용할 수 있는 자연어 프롬프트로 변환됩니다. KnowGPT 프레임워크는 도메인 특화 작업에서 성능을 향상시키면서 LLM의 API 호출 비용을 크게 줄입니다.

**StructTuning**은 2단계 전략으로 사전훈련된 모델에 도메인 지식을 임베딩하는 구조 인식 접근법을 사용합니다: 구조 인식 지속적 사전훈련은 지식을 모델의 파라미터로 인코딩하고, 구조 인식 지도 파인튜닝은 구조화된 QA 작업을 통해 이해를 정제합니다. 이 프레임워크는 관계 분류 및 질문 답변과 같은 지식 기반 작업에서 상당한 성능 향상을 보여주며, 일반성과 효율성 사이의 균형을 달성합니다.

**K-Adapter**는 어댑터 모듈 내에 지식을 저장합니다. 핵심 방법은 원래 모델 파라미터를 동결하고 각 유형의 지식에 대해 독립적이고 작업별 어댑터를 할당하는 것입니다. 이러한 어댑터는 특정 지식의 향상된 표현을 생성하기 위해 모델의 중간 레이어에 독립 모듈로 삽입됩니다. 이 설계는 새로 주입된 지식이 모델의 기존 지식을 덮어쓰는 것을 방지하여 재앙적 망각 문제를 효과적으로 완화합니다.

마지막으로, **SelfLift**는 무한한 메모리 풀을 생성하기 위해 검색 증강 생성기를 반복적으로 사용하고 메모리 선택기를 사용하여 다음 생성 라운드를 위한 메모리로 하나의 출력을 선택합니다. 이는 모델의 출력이 동적으로 정제되고 재사용되어 후속 작업에서 전반적인 성능과 일관성을 향상시키는 프롬프트 최적화의 좋은 시연입니다.

### 5.2 지식 소스 (Knowledge Source)

우리는 도메인 특화 LLM에 일반적으로 사용되는 지식 소스를 표 3에 요약합니다. 이는 정적 임베딩 또는 어댑터 튜닝을 위한 훈련 코퍼스, 동적 지식 주입을 위한 검색 또는 프롬프트 설계 리소스를 포함하여 다양한 주입 방법에 사용되는 외부 지식을 제공하는 데이터셋을 나타냅니다. 생물의학에는 질문 답변 및 임상 요약과 같은 작업을 지원하는 PubMed, PubMedQA(Jin et al., 2019), BioASQ(Tsatsaronis et al., 2012)와 같은 수많은 고품질 데이터셋이 포함됩니다.

대조적으로, 재료 및 화학은 더 제한된 리소스를 가지고 있으며, USPTO 및 Enzymes와 같은 데이터셋은 화학 반응에 초점을 맞춥니다. 기타 데이터셋은 정신 건강의 PsyQA 및 SmileChat, 교육의 SocraTeach 및 어린이 감정 교육 대화 데이터 데이터셋과 같은 다른 도메인에 흩어져 있습니다. 이러한 다양성은 LLM을 전문 분야에 맞게 조정하려는 노력을 강조하면서 대표성이 부족한 도메인에서 벤치마크의 더 넓은 큐레이션의 필요성을 강조합니다.

### 5.3 4가지 패러다임의 성능 비교 (Performance Comparison of 4 Paradigms)

**표 4: 의료 벤치마크에서 네 가지 지식 패러다임에 걸친 모델 성능**

| 모델 | 카테고리 | MedQA | PubMedQA | MedMCQA |
|------|----------|--------|-----------|----------|
| GPT-4 (Medprompt) | 프롬프트 최적화 | 90.2 | 82.0 | 79.1 |
| GPT-4 | 일반 | 90.2 | 80.4 | 73.7 |
| Med-PaLM 2 | 정적 지식 | 85.4 | 81.8 | 72.3 |
| Flan-PaLM (3-shot) | 동적 지식 | 67.6 | 79.0 | 57.6 |
| PMC-LLaMA | 정적 지식 | 56.3 | 77.9 | 56.0 |
| BioMedLM | 정적 지식 | 50.3 | 74.4 | – |
| LLaMA (MedAdapter) | 지식 어댑터 | 37.4 | 63.6 | 32.0 |

실제 환경에서 지식 주입 패러다임을 비교하기 위해, 우리는 MedQA, PubMedQA 및 MedMCQA와 같은 벤치마크의 가용성과 인기로 인해 생물의학 도메인에 초점을 맞춥니다(표 4 참조). 모델이 아키텍처에서 다르지만, 가능한 경우 백본을 정렬합니다. 예를 들어, PMC-LLaMA와 MedAdapter는 모두 LLaMA-13B를 사용합니다. GPT-4와 같은 SOTA 모델은 클로즈드 소스이므로 프롬프트 최적화가 유일한 실행 가능한 적응 전략입니다.

도메인 특화 훈련이 없음에도 불구하고, Medprompt를 사용한 GPT-4는 강력한 성능을 달성하여 클로즈드 모델에 대한 프롬프트 방법의 효과를 보여줍니다. 오픈 모델 중에서 MedAdapter는 PMC-LLaMA에 비해 성능이 떨어지며, 이는 일부 작업에서 전체 파인튜닝이 어댑터 기반 방법보다 우수할 수 있음을 시사합니다. 패러다임 간의 성능 차이는 특히 정적 주입 접근법에서 사전훈련 코퍼스와 작업 정렬의 중요성을 강조합니다. 또한 부록 A에서는 금융 도메인에서 지식 주입 패러다임을 비교하고 의료 도메인과 유사한 결론을 얻습니다.

## 6. 도전과 기회 (Challenges and Opportunities)

### 통합 지식 일관성 (Integrated Knowledge Consistency)

지식 주입은 LLM이 외부 사실로 추론할 수 있게 하지만, 검색된 지식이 모델의 사전훈련된 표현이나 다른 검색된 사실과 충돌할 수 있어 출력의 불일치를 초래합니다(Xu et al., 2024b). 예를 들어, 의료나 법률 분석에서 다른 임상 지침의 충돌하는 치료 프로토콜이나 모순되는 법적 선례가 발생할 수 있어(Dayton, 2012) 신뢰할 수 없는 결정을 초래하고 시스템의 신뢰성을 훼손할 수 있습니다. 이를 해결하기 위해 향후 연구는 불일치 감지, 충돌 해결 및 통합 지식의 일관성 유지에 초점을 맞춰야 합니다. 충돌은 신뢰할 수 있는 소스에 우선순위를 두거나, 도메인 특화 규칙을 적용하거나, 여러 관점의 균형을 맞추기 위해 앙상블 기술을 사용하여 해결할 수 있습니다. 정렬 및 검증 모듈은 검색된 지식이 모델의 추론에 맞는지 확인하는 데 도움이 됩니다.

### 도메인 간 지식 전이 (Cross-Domain Knowledge Transfer)

도메인 간 지식 전이는 LLM이 다양하고 구별되는 분야에 걸쳐 지식을 일반화할 수 있는 능력을 갖추는 것을 포함합니다(Li et al., 2025b). 이는 적용 가능성을 크게 확장하지만 도메인 특화 용어, 온톨로지 및 추론 패턴의 복잡성과 다양성으로 인해 도전 과제도 도입합니다(Montero et al., 2004). 예를 들어, 화학에서 의료로 지식을 전이하려면 용어 격차를 해소하는 것뿐만 아니라 다른 데이터 구조와 추론 프레임워크에 적응해야 할 수도 있습니다(Schroeder et al., 2018). 이러한 과제를 극복하려면 모듈식 지식 표현 및 전이 학습 기술의 발전이 필요합니다. 향후 노력은 정적 임베딩과 동적 검색을 혼합하는 하이브리드 접근법을 탐구할 수 있으며, 이를 통해 LLM이 깊이를 손상시키지 않고 도메인 간에 유연하게 지식을 적응시킬 수 있습니다. 또한 표준화된 도메인 간 벤치마크는 일관된 평가를 가능하게 하고 지식 전이 방법의 혁신을 추진할 수 있습니다.

부록 B에서 더 많은 논의를 제공합니다.

## 7. 결론 (Conclusion)

도메인 특화 지식으로 향상된 LLM은 놀라운 잠재력을 보여주었고 연구 관심이 증가하고 있습니다. 이 서베이는 LLM 지식 주입 시스템을 체계적으로 검토하여 지식 표현 방법, 통합 전략 및 모델 일반성 보존 메커니즘을 탐구합니다. 우리는 또한 생물의학, 화학 및 전산 사회 과학 도메인에 걸친 응용 프로그램을 요약합니다. 표준 데이터셋, 벤치마크, 도전 과제 및 향후 기회를 강조함으로써, 우리는 도메인 특화 도전을 위한 지식 향상 LLM의 탐구에 영감을 주는 귀중한 리소스를 제공하는 것을 목표로 합니다.

## 제한사항 (Limitation)

LLM의 도메인 특화 지식 주입을 위한 현재 방법과 응용 프로그램에 대한 포괄적인 검토를 제공함에도 불구하고, 이 서베이에는 특정 제한사항이 있습니다. 첫째, 우리는 금융, 생물의학 및 재료 과학과 같은 여러 주요 도메인을 다루려고 노력하지만, 일부 덜 연구되거나 새롭게 떠오르는 영역(예: 저자원 언어, 문화 간 교육 및 틈새 분야)은 상대적으로 제한된 관심을 받습니다. 둘째, 우리의 초점은 주로 기존 문헌에서 방법론적 원칙과 대표 모델을 요약하는 것입니다. 모델 아키텍처, 응용 도메인, 훈련 데이터 및 평가 프로토콜의 상당한 변화로 인해, 우리는 일반적으로 채택된 데이터셋을 사용하여 생물의학 도메인 내에서 통제된 조건 하에서만 대상 비교를 수행할 수 있었습니다. 방법 간의 보다 체계적이고 광범위한 경험적 평가는 향후 작업의 중요한 방향으로 남아 있습니다. 그럼에도 불구하고, 우리는 이 서베이가 유용한 참고 자료로 사용되고 지식 향상 LLM의 지속적인 연구를 위한 명확한 로드맵을 제공하기를 희망합니다.

## 감사의 글 (Acknowledgement)

익명의 리뷰어들의 건설적인 의견에 감사드립니다. 이 작업은 Mohamed bin Zayed University of Artificial Intelligence (MBZUAI)의 보조금 수상 8481000078을 통해 지원되었습니다.

## 부록 A: 4가지 패러다임의 성능 비교 (금융)

**표 5: 금융 벤치마크에서 네 가지 지식 주입 패러다임 하의 대표 모델의 성능 비교**

| 모델 | 카테고리 | FPB | FiQA-SA | TFNS |
|------|----------|-----|---------|------|
| GPT-4 | 일반 | 83.3 | 63.0 | 80.8 |
| GPT-4(finetune) | 정적 지식 | 87.8 | 88.7 | 88.3 |
| FinGPT | 지식 어댑터 | 88.2 | 87.4 | 90.3 |
| FinBERT | 정적 지식 | 88.0 | 59.6 | 73.3 |
| BloombergGPT | 정적 지식 | 51.1 | 75.1 | - |
| Llama2-7B | 일반 | 39.0 | 80.0 | 29.6 |
| FLANG | 정적 지식 | 91.9 | 3.4 | - |

실제 환경에서 다양한 지식 주입 패러다임의 효과를 체계적으로 비교하기 위해, 우리는 생물의학과 금융이라는 두 가지 대표적인 도메인에 초점을 맞춥니다.

널리 연구되고 벤치마크 데이터셋(예: MedQA, PubMedQA, MedMCQA)이 풍부한 생물의학 도메인에서 우리는 다양한 모델의 성능을 평가합니다(표 4 참조). 모델이 아키텍처에서 다르지만, 가능한 경우 백본을 정렬합니다—예를 들어, PMC-LLaMA와 MedAdapter는 모두 LLaMA-13B를 사용합니다. GPT-4와 같은 클로즈드 소스 모델의 경우 프롬프트 엔지니어링이 유일한 실행 가능한 적응 전략입니다. 그럼에도 불구하고 Medprompt와 결합된 GPT-4는 강력한 성능을 달성하여 프롬프트 기반 지식 주입의 효과를 입증합니다. 오픈 모델 중에서 MedAdapter는 PMC-LLaMA와 같은 완전히 파인튜닝된 모델에 비해 성능이 떨어지며, 이는 전체 파인튜닝이 특정 작업에서 어댑터 기반 방법보다 더 효과적일 수 있음을 시사합니다. 정적 지식을 가진 모델(예: MedBERT)은 작업 전반에 걸쳐 상당한 변동을 보이며, 사전훈련 코퍼스와 다운스트림 목표 간의 정렬의 중요성을 강조합니다.

표 5에서 우리는 이 비교를 금융 도메인으로 확장하여 FPB(Malo et al., 2014), FiQA-SA(Maia et al., 2018) 및 TFNS(El-Haj et al., 2020)와 같은 벤치마크에서 모델을 평가합니다. 결과는 생물의학 도메인의 결과를 밀접하게 반영합니다. 파인튜닝된 GPT-4는 일관되게 다른 모델을 능가하여 범용 LLM에 도메인 특화 지식을 주입하는 가치를 확인합니다. FinBERT 및 FLANG과 같은 정적 지식 모델은 특정 작업에서 잘 수행되지만 상당한 변동성을 보이며, 다시 한 번 코퍼스-작업 정렬의 중요한 역할을 강조합니다. 가벼운 어댑터 기반 지식 주입을 채택하는 FinGPT는 적응성을 유지하면서 경쟁력 있는 성능을 달성합니다. 대조적으로, LLaMA2-7B는 대부분의 작업에서 뒤처지며, 도메인 집약적 응용 프로그램에 대한 대상 지식 주입의 필요성을 강화합니다. 두 도메인 전반에 걸친 관찰의 일관성은 지식 주입의 효과가 복잡하고 위험이 높은 작업을 지원하기 위해 아키텍처 설계, 적응 전략 및 코퍼스 정렬의 신중한 균형에 달려 있음을 시사합니다.

## 부록 B: 도전과 기회에 대한 자세한 논의

### B.1 통합 지식 일관성 (Integrated Knowledge Consistency)

지식 주입은 LLM이 외부 사실로 추론할 수 있도록 하지만, 중요한 일관성 문제를 도입합니다: 주입된 지식이 모델의 내부 표현이나 다른 검색된 정보와 모순될 수 있습니다(Xu et al., 2024b). 의료 및 법률과 같은 고위험 도메인에서는 사소한 불일치도 상당한 결과를 초래할 수 있습니다—예를 들어, 다른 임상 지침의 충돌하는 약물 용량(Dayton, 2012; Zhao et al., 2025) 또는 관할권 간의 다른 법적 해석(Guha et al., 2023).

최근 연구는 사후 검색 모순 감지(Xu et al., 2024a) 및 신뢰도 인식 재순위(Ren et al., 2025)와 같은 기술을 제안합니다. MedRAG(Zhao et al., 2025)와 같은 일부 프레임워크는 신뢰할 수 있는 소스에 우선순위를 두기 위해 가중 검색과 앙상블 투표를 적용합니다. 다른 사람들은 주입된 지식이 사전 정의된 온톨로지에 정렬되거나 구조화된 추론 경로를 사용하여 검증되는 신경 기호 일관성 검사를 탐구합니다(Ciatto et al., 2024).

또 다른 성장하는 영역은 검색된 문서가 LLM의 중간 신념과의 정렬을 기반으로 필터링되는 정렬 인식 재순위를 포함합니다(Jin et al., 2025). 향후 방향에는 대화형 일관성 해결(예: 사용자 개입 충돌 선택)과 디코딩 중 사실성을 명시적으로 모니터링하는 사실 보정 모듈 통합(Dong et al., 2022)이 포함될 수 있습니다. 이러한 방법들은 집합적으로 지식 향상 LLM을 동적이거나 민감한 환경에서 더 견고하고 설명 가능하며 신뢰할 수 있도록 만드는 것을 목표로 합니다.

### B.2 도메인 간 지식 전이 (Cross-Domain Knowledge Transfer)

도메인 간 전이는 일반화되면서도 전문화된 LLM을 구축하는 데 있어 중심적인 도전입니다. LLM이 다양한 도메인의 지식에 노출되면서, 호환되지 않는 온톨로지, 다양한 도메인 언어 및 구별되는 추론 구조를 탐색해야 합니다(Li et al., 2025b). 예를 들어, 화학에서 의료로 개념을 전이하려면 용어 격차를 해소하는 것뿐만 아니라 다른 인과 가정과 데이터 형식에 적응해야 합니다(Schroeder et al., 2018).

이러한 복잡성을 관리하기 위해 여러 전략이 제안되었습니다. 어댑터 기반 모듈화(He et al., 2021)는 도메인 특화 구성 요소를 별도로 훈련하고 선택적으로 활성화할 수 있게 합니다. 메타 학습 접근법(Hou et al., 2022)은 모델이 최소한의 감독으로 새로운 도메인에 빠르게 적응하는 데 도움이 됩니다. 또한 혼합 도메인 코퍼스에 대한 지속적인 사전훈련(Jin et al., 2022)은 재앙적 망각 없이 견고성을 향상시키는 확장 가능한 방법을 제공합니다.

다국어 명명된 엔티티 인식을 위한 CrossNER(Liu et al., 2021), 도메인 간 요약을 위한 MultiLexSum(Shen et al., 2022), 생물의학 QA를 위한 MEDIQA-QA(Yadav et al., 2021)와 같은 표준화된 데이터셋은 도메인 간 평가를 위한 귀중한 테스트베드 역할을 합니다. 향후 작업은 도메인 관련 지식의 동적 선택이 적응적 추론을 지원하는 검색 증강 전이 또는 LLM이 명시적 감독 없이 작업 전반에 걸쳐 일반화할 수 있게 하는 도메인 불변 임베딩 학습을 탐구할 수 있습니다.

### B.3 지식 통합의 확장성과 효율성 (Scalability and Efficiency of Knowledge Integration)

LLM이 전체 지식 그래프, 문서 코퍼스 또는 실시간 검색 API와 같은 대규모 외부 지식으로 점점 더 증강됨에 따라, 이 지식을 통합하는 계산 및 메모리 비용이 병목 현상이 됩니다. 특히 저자원 또는 지연 시간 제한 설정에서 작동할 때 효율적인 통합이 주요 과제로 남아 있습니다.

희소 검색(Lee et al., 2019), 메모리 압축(Zhong et al., 2024) 및 캐싱 전략과 같은 기술이 오버헤드를 줄이기 위해 제안되었습니다. 모듈식 아키텍처(예: 어댑터 또는 플러그인 모듈)도 지식의 부분 활성화를 허용하여 확장성을 향상시킵니다. 향후 연구는 외부 지식의 작업 인식 가지치기, 검색 기반 파이프라인에서 컴팩트 모델로의 지식 증류, 각 입력에 대해 관련 지식만 선택하는 효율적인 라우팅 메커니즘을 탐구할 수 있습니다.

### B.4 평가 및 환각 감지 (Evaluation and Hallucination Detection)

지식 향상 LLM을 평가하는 것은 사실 일관성, 범위 및 추론 깊이에 대한 표준화된 벤치마크와 자동 메트릭이 부족하여 여전히 어렵습니다. 또한 LLM은 정확한 지식으로 증강된 경우에도 종종 사실을 환각합니다(Ji et al., 2023), 이는 고위험 작업에서 출력을 신뢰하기 어렵게 만듭니다.

최근 작업은 FactScore(Min et al., 2023), 함의 기반 검증(Patwa et al., 2022) 및 인간 개입 평가 체계와 같은 메트릭을 탐구합니다. 그러나 이러한 방법 중 일부는 도메인이나 언어 전반에 걸쳐 확장됩니다. 모델이 검색된 지식을 효과적이고 진실되게 사용했는지 여부를 포착하는 작업별, 세밀한 평가 메트릭에 대한 필요성이 증가하고 있습니다. 또한 생성과 소스 지식 간의 일관성 검사와 같은 내부 모듈로서 환각 감지를 통합하면 위험을 줄이고 상호 운용성을 향상시킬 수 있습니다.